{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN4ZpPHzMgW31Gi72479oSc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bO0BRyrejGdN"},"outputs":[],"source":["!pip install -q --upgrade datasets==3.6.0"]},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","  if gpu_info.find('Tesla T4') >= 0:\n","    print(\"Success - Connected to a T4\")\n","  else:\n","    print(\"NOT CONNECTED TO A T4\")"],"metadata":{"id":"lrCbi8AJjbol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from google.colab import userdata\n","from huggingface_hub import login\n","from transformers import pipeline\n","from diffusers import DiffusionPipeline\n","from datasets import load_dataset\n","import soundfile as sf\n","from IPython.display import Audio"],"metadata":{"id":"KfI7DhBRkuUa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hf_token = userdata.get('HuggingFace')\n","if hf_token and hf_token.startswith(\"hf_\"):\n","  print(\"HF key looks good so far\")\n","else:\n","  print(\"HF key is not set - please click the key in the left sidebar\")\n","login(hf_token, add_to_git_credential=True)"],"metadata":{"id":"i3kuSjNdmTzA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_simple_sentiment_analyzer = pipeline(\"sentiment-analysis\", device=\"cuda\")\n","result = my_simple_sentiment_analyzer(\"I'm super excited to be on the way to LLM mastery!\")\n","print(result)"],"metadata":{"id":"oG4uetP3mxXh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = my_simple_sentiment_analyzer(\"I should be more excited to be on the way to LLM mastery!\")\n","print(result)"],"metadata":{"id":"Z5W2wbwym0UZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["better_sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\", device=\"cuda\")\n","result = better_sentiment(\"I should be more excited to be on the way to LLM mastery!!\")\n","print(result)"],"metadata":{"id":"Gf7DLW45nU2J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Named Entity Recognition\n","\n","ner = pipeline(\"ner\", device=\"cuda\")\n","result = ner(\"AI Engineers are learning about the amazing pipelines from HuggingFace in Google Colab from Ed Donner\")\n","for entity in result:\n","  print(entity)"],"metadata":{"id":"2cUL2jp1oEe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question=\"What are Hugging Face pipelines?\"\n","context=\"Pipelines are a high level API for inference of LLMs with common tasks\"\n","\n","question_answerer = pipeline(\"question-answering\", device=\"cuda\")\n","result = question_answerer(question=question, context=context)\n","print(result)"],"metadata":{"id":"IHPbrWl6or_L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text Summarization\n","\n","summarizer = pipeline(\"summarization\", device=\"cuda\")\n","text = \"\"\"\n","The Hugging Face transformers library is an incredibly versatile and powerful tool for natural language processing (NLP).\n","It allows users to perform a wide range of tasks such as text classification, named entity recognition, and question answering, among others.\n","It's an extremely popular library that's widely used by the open-source data science community.\n","It lowers the barrier to entry into the field by providing Data Scientists with a productive, convenient way to work with transformer models.\n","\"\"\"\n","summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n","print(summary[0]['summary_text'])"],"metadata":{"id":"lMDTWNkEowg8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Translation\n","\n","translator = pipeline(\"translation_en_to_fr\", device=\"cuda\")\n","result = translator(\"The Data Scientists were truly amazed by the power and simplicity of the HuggingFace pipeline API.\")\n","print(result[0]['translation_text'])"],"metadata":{"id":"CkAi23jjpY_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Another translation, showing a model being specified\n","# All translation models are here: https://huggingface.co/models?pipeline_tag=translation&sort=trending\n","\n","translator = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\", device=\"cuda\")\n","result = translator(\"The Data Scientists were truly amazed by the power and simplicity of the HuggingFace pipeline API.\")\n","print(result[0]['translation_text'])"],"metadata":{"id":"nas2W4Mvprq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Classification\n","\n","classifier = pipeline(\"zero-shot-classification\", device=\"cuda\")\n","result = classifier(\"Hugging Face's Transformers library is amazing!\", candidate_labels=[\"technology\", \"sports\", \"politics\"])\n","print(result)"],"metadata":{"id":"9pzbFmuYp74d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Text Generation\n","\n","generator = pipeline(\"text-generation\", device=\"cuda\")\n","result = generator(\"If there's one thing I want you to remember about using HuggingFace pipelines, it's\")\n","print(result[0]['generated_text'])"],"metadata":{"id":"pmDQfLw7rl5y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image Generation - remember this?! Now you know what's going on\n","# Pipelines can be used for diffusion models as well as transformers\n","\n","from IPython.display import display\n","from diffusers import AutoPipelineForText2Image\n","import torch\n","\n","pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\")\n","pipe.to(\"cuda\")\n","prompt = \"A class of students learning AI engineering in a vibrant pop-art style\"\n","image = pipe(prompt=prompt, num_inference_steps=4, guidance_scale=0.0).images[0]\n","display(image)"],"metadata":{"id":"AbQaR5mutgfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Audio Generation\n","\n","from transformers import pipeline\n","from datasets import load_dataset\n","import soundfile as sf\n","import torch\n","from IPython.display import Audio\n","\n","synthesiser = pipeline(\"text-to-speech\", \"microsoft/speecht5_tts\", device='cuda')\n","embeddings_dataset = load_dataset(\"matthijs/cmu-arctic-xvectors\", split=\"validation\", trust_remote_code=True)\n","speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n","speech = synthesiser(\"Hi to an artificial intelligence engineer, on the way to mastery!\", forward_params={\"speaker_embeddings\": speaker_embedding})\n","\n","Audio(speech[\"audio\"], rate=speech[\"sampling_rate\"])"],"metadata":{"id":"ouGLL4not9SB"},"execution_count":null,"outputs":[]}]}