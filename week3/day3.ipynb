{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMhzx2fcYdRiXdSjeoExIDj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zyRFcCtL1Bdo"},"outputs":[],"source":["from google.colab import userdata\n","from huggingface_hub import login\n","from transformers import AutoTokenizer"]},{"cell_type":"code","source":["hf_token = userdata.get('HuggingFace')\n","if hf_token and hf_token.startswith(\"hf_\"):\n","  print(\"HF key looks good so far\")\n","else:\n","  print(\"HF key is not set - please click the key in the left sidebar\")\n","login(hf_token, add_to_git_credential=True)\n","\n","# Check Google Colab GPU\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","  if gpu_info.find('Tesla T4') >= 0:\n","    print(\"Success - Connected to a T4\")\n","  else:\n","    print(\"NOT CONNECTED TO A T4\")"],"metadata":{"id":"xINu7KsW1jjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-235B-A22B-Thinking-2507-FP8', trust_remote_code=True)"],"metadata":{"id":"hdhhyGi41s7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"I am excited to show Tokenizers in action to my LLM engineers\"\n","tokens = tokenizer.encode(text)\n","tokens"],"metadata":{"id":"FHQxLtCo4c9c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["character_count = len(text)\n","word_count = len(text.split(' '))\n","token_count = len(tokens)\n","print(f\"There are {character_count} characters, {word_count} words and {token_count} tokens\")"],"metadata":{"id":"-TA6vJrs4r0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.decode(tokens)"],"metadata":{"id":"xof6c8Bn5pYB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.batch_decode(tokens)"],"metadata":{"id":"M3DpONiE5zEn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenizer.vocab\n","tokenizer.get_added_vocab()"],"metadata":{"id":"Aof_2nlB55Sx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(tokenizer.vocab)"],"metadata":{"id":"881G4u1g59P9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-235B-A22B-Instruct-2507-FP8', trust_remote_code=True)"],"metadata":{"id":"ZbU9e6Of7NqH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n","    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n","  ]\n","\n","prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","print(prompt)"],"metadata":{"id":"6qZ_p36L7T6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PHI4 = \"microsoft/Phi-4-mini-instruct\"\n","DEEPSEEK = \"deepseek-ai/DeepSeek-V3.1\""],"metadata":{"id":"hmZuJrcB8K5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["phi4_tokenizer = AutoTokenizer.from_pretrained(PHI4)\n","\n","text = \"I am curiously excited to show Hugging Face Tokenizers in action to my LLM engineers\"\n","print(\"Qwen:\")\n","tokens = tokenizer.encode(text)\n","print(tokens)\n","print(tokenizer.batch_decode(tokens))\n","print(\"\\nPhi 4:\")\n","tokens = phi4_tokenizer.encode(text)\n","print(tokens)\n","print(phi4_tokenizer.batch_decode(tokens))"],"metadata":{"id":"Y4VzojvE8Pzx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Qwen:\")\n","print(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n","print(\"\\nPhi 4:\")\n","print(phi4_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))"],"metadata":{"id":"ifv5L4f28ciS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["deepseek_tokenizer = AutoTokenizer.from_pretrained(DEEPSEEK)\n","\n","text = \"I am curiously excited to show Hugging Face Tokenizers in action to my LLM engineers\"\n","print(tokenizer.encode(text))\n","print()\n","print(phi4_tokenizer.encode(text))\n","print()\n","print(deepseek_tokenizer.encode(text))"],"metadata":{"id":"PRz-AApV8kiN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Qwen:\")\n","print(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n","print(\"\\nPhi:\")\n","print(phi4_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n","print(\"\\nDeepSeek:\")\n","print(deepseek_tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))"],"metadata":{"id":"DCIsV86x8odw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ASHRA-yd80nM"},"execution_count":null,"outputs":[]}]}